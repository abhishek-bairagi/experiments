{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Elasticsearch endpoint\n",
    "es_url = \"http://localhost:9200/products\"\n",
    "\n",
    "# Sample data file (replace with actual JSON data or load dynamically)\n",
    "with open('products.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create index with basic mapping (optional)\n",
    "index_mapping = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"product_id\": {\"type\": \"keyword\"},\n",
    "            \"name\": {\"type\": \"text\"},\n",
    "            \"price\": {\"type\": \"float\"},\n",
    "            \"category\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check if index exists\n",
    "response = requests.head(es_url)\n",
    "if response.status_code == 404:  # Index does not exist\n",
    "    create_index_response = requests.put(es_url, json=index_mapping)\n",
    "    if create_index_response.status_code == 200:\n",
    "        print(\"Index 'products' created successfully\")\n",
    "    else:\n",
    "        print(\"Failed to create index:\", create_index_response.text)\n",
    "\n",
    "# Bulk ingest data\n",
    "bulk_data = \"\"\n",
    "for product in data:\n",
    "    bulk_data += json.dumps({\"index\": {\"_id\": product[\"product_id\"]}}) + \"\\n\"\n",
    "    bulk_data += json.dumps(product) + \"\\n\"\n",
    "\n",
    "bulk_response = requests.post(f\"{es_url}/_bulk\", headers={\"Content-Type\": \"application/json\"}, data=bulk_data)\n",
    "if bulk_response.status_code == 200:\n",
    "    print(\"Data ingested into Elasticsearch index 'products'\")\n",
    "else:\n",
    "    print(\"Failed to ingest data:\", bulk_response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"password\"  # replace with your Neo4j password\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "with open('products.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def ingest_product(tx, product):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (p:Product {id: $id})\n",
    "        SET p.name = $name, p.category = $category, p.vendor = $vendor\n",
    "    \"\"\", id=product['product_id'], name=product['name'], category=product['category'], vendor=product['vendor'])\n",
    "\n",
    "    for subtopic in product.get('subtopics', []):\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (p:Product {id: $pid})\n",
    "            MERGE (s:Subtopic {id: $sid})\n",
    "            SET s.name = $sname\n",
    "            MERGE (p)-[:HAS_SUBTOPIC]->(s)\n",
    "        \"\"\", pid=product['product_id'], sid=subtopic['subtopic_id'], sname=subtopic['name'])\n",
    "\n",
    "        for issue in subtopic.get('issues', []):\n",
    "            tx.run(\"\"\"\n",
    "                MATCH (s:Subtopic {id: $sid})\n",
    "                MERGE (i:Issue {id: $iid})\n",
    "                SET i.title = $title, i.description = $desc\n",
    "                MERGE (s)-[:HAS_ISSUE]->(i)\n",
    "            \"\"\", sid=subtopic['subtopic_id'], iid=issue['issue_id'], title=issue['title'], desc=issue['description'])\n",
    "\n",
    "            for cause in issue.get('root_causes', []):\n",
    "                tx.run(\"\"\"\n",
    "                    MATCH (i:Issue {id: $iid})\n",
    "                    MERGE (r:RootCause {id: $rcid})\n",
    "                    SET r.description = $desc, r.probability = $prob\n",
    "                    MERGE (i)-[:HAS_ROOT_CAUSE]->(r)\n",
    "                \"\"\", iid=issue['issue_id'], rcid=cause['cause_id'], desc=cause['description'], prob=cause['probability'])\n",
    "\n",
    "            for step in issue.get('solution_steps', []):\n",
    "                tx.run(\"\"\"\n",
    "                    MATCH (i:Issue {id: $iid})\n",
    "                    MERGE (ss:SolutionStep {id: $ssid})\n",
    "                    SET ss.description = $desc, ss.order = $order\n",
    "                    MERGE (i)-[:HAS_SOLUTION_STEP]->(ss)\n",
    "                \"\"\", iid=issue['issue_id'], ssid=step['step_id'], desc=step['description'], order=step['order'])\n",
    "\n",
    "            for article in issue.get('articles', []):\n",
    "                tx.run(\"\"\"\n",
    "                    MATCH (i:Issue {id: $iid})\n",
    "                    MERGE (a:Article {id: $aid})\n",
    "                    SET a.title = $title, a.summary = $summary, a.url = $url\n",
    "                    MERGE (i)-[:HAS_ARTICLE]->(a)\n",
    "                \"\"\", iid=issue['issue_id'], aid=article['article_id'], title=article['title'], summary=article['summary'], url=article['url'])\n",
    "\n",
    "with driver.session() as session:\n",
    "    for product in data:\n",
    "        session.write_transaction(ingest_product, product)\n",
    "\n",
    "print(\"Data ingested into Neo4j\")\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# ======= LLM wrapper (your own function) =======\n",
    "def generate_text(prompt):\n",
    "    # Your LLM inference logic here\n",
    "    raise NotImplementedError(\"Replace with your LLM call\")\n",
    "\n",
    "# ======= Elasticsearch Query via requests =======\n",
    "def search_elasticsearch(query, top_k=3):\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content\": {\n",
    "                    \"query\": query\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"size\": top_k\n",
    "    }\n",
    "    res = requests.get(\n",
    "        \"http://localhost:9200/products/_search\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        data=json.dumps(body)\n",
    "    )\n",
    "    hits = res.json().get(\"hits\", {}).get(\"hits\", [])\n",
    "    return [hit[\"_source\"] for hit in hits]\n",
    "\n",
    "# ======= Neo4j Cypher Runner =======\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
    "\n",
    "def run_cypher_query(cypher_query):\n",
    "    def fetch(tx):\n",
    "        result = tx.run(cypher_query)\n",
    "        return [record.data() for record in result]\n",
    "    with driver.session() as session:\n",
    "        return session.read_transaction(fetch)\n",
    "\n",
    "# ======= LLM-powered Functions =======\n",
    "\n",
    "def extract_query_details(user_query):\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent assistant that extracts key information from user queries related to IT issues.\n",
    "\n",
    "User query: \"{user_query}\"\n",
    "\n",
    "Extract the following as JSON:\n",
    "- product\n",
    "- subtopic (if any)\n",
    "- intent/issue in plain text\n",
    "\n",
    "Return only valid JSON.\n",
    "\"\"\"\n",
    "    response = generate_text(prompt)\n",
    "    return json.loads(response)\n",
    "\n",
    "def generate_cypher_query(details):\n",
    "    prompt = f\"\"\"\n",
    "You are a graph query generator. Given the following extracted info:\n",
    "\n",
    "Product: {details['product']}\n",
    "Subtopic: {details.get('subtopic')}\n",
    "Issue description: {details['intent']}\n",
    "\n",
    "Generate a Cypher query that:\n",
    "- Matches the product node\n",
    "- Traverses subtopics and issues\n",
    "- Optionally matches root causes, solution steps, and articles\n",
    "Return the full Cypher query only, no explanation.\n",
    "\"\"\"\n",
    "    return generate_text(prompt).strip()\n",
    "\n",
    "def match_relevant_issue(user_query, candidate_issues):\n",
    "    prompt = f\"\"\"\n",
    "A user asked: \"{user_query}\"\n",
    "\n",
    "Here are candidate issues from the knowledge graph:\n",
    "{json.dumps(candidate_issues, indent=2)}\n",
    "\n",
    "From this list, pick the best matching issue. Return a JSON:\n",
    "- matched_issue_title\n",
    "- why_it_matches (1-2 lines)\n",
    "\"\"\"\n",
    "    return json.loads(generate_text(prompt))\n",
    "\n",
    "def generate_final_answer(user_query, kg_info, es_articles):\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful IT assistant.\n",
    "\n",
    "User query: \"{user_query}\"\n",
    "\n",
    "Knowledge Graph Info:\n",
    "- Issue: {kg_info.get('matched_issue_title')}\n",
    "- Reasoning: {kg_info.get('why_it_matches')}\n",
    "\n",
    "Self-help Articles:\n",
    "{json.dumps(es_articles, indent=2)}\n",
    "\n",
    "Use all the above to generate a helpful response to the user in clear language.\n",
    "\"\"\"\n",
    "    return generate_text(prompt)\n",
    "\n",
    "# ======= Full Pipeline =======\n",
    "\n",
    "def full_pipeline(user_query):\n",
    "    details = extract_query_details(user_query)\n",
    "\n",
    "    cypher = generate_cypher_query(details)\n",
    "    candidate_issues = run_cypher_query(cypher)\n",
    "\n",
    "    kg_match = match_relevant_issue(user_query, candidate_issues)\n",
    "\n",
    "    es_docs = search_elasticsearch(user_query)\n",
    "\n",
    "    final_answer = generate_final_answer(user_query, kg_match, es_docs)\n",
    "    return final_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"My audio is not working in Webex during meetings\"\n",
    "response = full_pipeline(user_query)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
