{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526c06be-5944-4066-a636-e989954b36cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj facing PRON I\n",
      "am aux facing AUX be\n",
      "facing ROOT facing VERB face\n",
      "issues dobj facing NOUN issue\n",
      "with prep issues ADP with\n",
      "slack pobj with NOUN slack\n",
      ". punct facing PUNCT .\n",
      "Facing ROOT Facing VERB face\n",
      "background compound echo NOUN background\n",
      "audio compound echo NOUN audio\n",
      "echo dobj Facing NOUN echo\n",
      ". punct Facing PUNCT .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "utterance = \"I am facing issues with slack. Facing background audio echo.\"\n",
    "doc = nlp(utterance)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.pos_, token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a19cef-5fed-4c3d-a3a9-b8148d7b9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6e5189d-673b-4a6e-87ad-7481b6a45034",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_concepts = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ in (\"VERB\", \"NOUN\", \"PROPN\") and token.dep_ in (\"ROOT\", \"dobj\", \"pobj\", \"nsubj\", \"attr\"):\n",
    "        concept = token.lemma_.lower()\n",
    "        core_concepts.append(concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a524222e-4c83-4e9f-99c8-df018c7b61f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face', 'issue', 'slack', 'face', 'echo']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5bdf82-52f5-4458-a85d-dac871f57c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add directed edges: head → dependent\n",
    "for token in doc:\n",
    "    if token.pos_ in (\"VERB\", \"NOUN\", \"PROPN\"):\n",
    "        head = token.head.lemma_.lower()\n",
    "        child = token.lemma_.lower()\n",
    "        if head != child:\n",
    "            G.add_edge(head, child, label=token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71acfacb-3fd6-4684-bccc-d3a14c0294c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find root verb\n",
    "root = [token.lemma_.lower() for token in doc if token.dep_ == \"ROOT\"]\n",
    "paths = []\n",
    "\n",
    "for r in root:\n",
    "    for target in G.successors(r):\n",
    "        path = [r, target]\n",
    "        for next_node in G.successors(target):\n",
    "            path.append(next_node)\n",
    "        paths.append(\" \".join(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36756191-5862-4c87-8092-444e093deb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face issue',\n",
       " 'face echo background audio',\n",
       " 'face issue',\n",
       " 'face echo background audio']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfbdff3-6f00-46f7-855c-d31af107dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['team', 'need', 'laptop', 'check', 'key', 'work', 'need', 'file', 'ticket']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def extract_important_words(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    important_words = []\n",
    "\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            if token.pos_ in (\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"):\n",
    "                important_words.append(token.lemma_.lower())\n",
    "\n",
    "    return important_words\n",
    "\n",
    "# Example\n",
    "text = \"I am facing issues with slack. How to remove background echo\"\n",
    "print(extract_important_words(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bad6f880-a24f-4de7-bb71-9147b0ada9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face', 'issue', 'slack', 'remove', 'background', 'echo']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_important_words(text):\n",
    "    doc = nlp(text)\n",
    "    important_words = []\n",
    "\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "\n",
    "        # Keep informative nouns, adjectives, and main verbs\n",
    "        if token.pos_ in (\"NOUN\", \"PROPN\", \"ADJ\"):\n",
    "            important_words.append(lemma)\n",
    "        elif token.pos_ == \"VERB\" and token.dep_ in (\"ROOT\", \"xcomp\", \"acl\", \"advcl\"):\n",
    "            important_words.append(lemma)\n",
    "\n",
    "    return important_words\n",
    "\n",
    "# Example\n",
    "text = \"I am facing issues with slack. How to remove background echo\"\n",
    "print(extract_important_words(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "557f1b65-5f38-4a08-8532-70229a49f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting RapidFuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp39-cp39-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 614 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: RapidFuzz\n",
      "Successfully installed RapidFuzz-3.13.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/abhishekbairagi/Desktop/exp/envs/base/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install RapidFuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd0aab50-1e52-46e0-ba8e-b90365559b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('iPhone', 60.00000000000001, 0), None, None, ('iPhone', 72.72727272727273, 0), None, ('Galaxy', 61.53846153846154, 1)]\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import process\n",
    "\n",
    "keywords = ['iPhone', 'Galaxy', 'Pixel']\n",
    "text = \"He purchased an ipone and galaxi.\"\n",
    "tokens = text.split()\n",
    "\n",
    "matched = [\n",
    "    process.extractOne(token, keywords, score_cutoff=60)\n",
    "    for token in tokens\n",
    "]\n",
    "\n",
    "print(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb65b0f2-6739-40dc-81a5-44cd11490631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iPhone 14', 'iPhone 14', 'Galaxy S23']\n"
     ]
    }
   ],
   "source": [
    "from flashtext import KeywordProcessor\n",
    "\n",
    "keyword_processor = KeywordProcessor()\n",
    "\n",
    "# Dictionary: {alias: standard form}\n",
    "keyword_dict = {\n",
    "    'iPhone 14': ['iPhone', 'pixel'],\n",
    "    'iPhone 15': ['iPhone15'],\n",
    "    'Galaxy S22': ['Galaxy'],\n",
    "    'Galaxy S23': ['Galaxies']\n",
    "}\n",
    "\n",
    "keyword_processor.add_keywords_from_dict(keyword_dict)\n",
    "\n",
    "text = \"He bought an iPhone 14 and pixel and she prefers the Galaxies S23.\"\n",
    "\n",
    "print(keyword_processor.extract_keywords(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a014d99c-5838-4d50-a431-ac5b80cea674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "Using legacy 'setup.py install' for flashtext, since package 'wheel' is not installed.\n",
      "Installing collected packages: flashtext\n",
      "    Running setup.py install for flashtext ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed flashtext-2.7\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/abhishekbairagi/Desktop/exp/envs/base/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bde66-c55e-4680-acf1-ae697eec1f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
